{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1YE6Q5U5JgmcQEai9lWuR2462JpK7ug5y",
      "authorship_tag": "ABX9TyOszhyfPGewbn2hDZ+HurlP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yassine-cherni/Self-Driving-Car-Focus-/blob/main/YOLOV8_TRAFFIC_SIGN_V2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZJ84JcwF15Qw",
        "outputId": "12f96ae4-eef0-4d15-d6a6-741a60a5627b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.2.2-py3-none-any.whl (750 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m750.8/750.8 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (3.7.1)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.8.0.76)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.4.0)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (6.0.1)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.31.0)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (1.11.4)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.2.1+cu121)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.17.1+cu121)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (4.66.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from ultralytics) (9.0.0)\n",
            "Collecting thop>=0.1.1 (from ultralytics)\n",
            "  Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (2.0.3)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from ultralytics) (0.13.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.4->ultralytics) (2024.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.23.0->ultralytics) (2024.2.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.13.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->ultralytics) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.8.0->ultralytics)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, thop, ultralytics\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 thop-0.1.1.post2209072238 ultralytics-8.2.2\n"
          ]
        }
      ],
      "source": [
        "!pip install ultralytics"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Essential Libraries\n",
        "import os\n",
        "import random\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import cv2\n",
        "from ultralytics import YOLO\n",
        "from IPython.display import Video\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set(style='darkgrid')\n",
        "import pathlib\n",
        "import glob\n",
        "from tqdm.notebook import trange, tqdm\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "bTJX49762Zqz"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Image_dir = '/content/drive/MyDrive/Traffic/train/images'\n",
        "\n",
        "num_samples = 9\n",
        "image_files = os.listdir(Image_dir)\n",
        "\n",
        "# Randomly select num_samples images\n",
        "rand_images = random.sample(image_files, num_samples)\n",
        "\n",
        "fig, axes = plt.subplots(3, 3, figsize=(11, 11))\n",
        "\n",
        "for i in range(num_samples):\n",
        "    image = rand_images[i]\n",
        "    ax = axes[i // 3, i % 3]\n",
        "    ax.imshow(plt.imread(os.path.join(Image_dir, image)))\n",
        "    ax.set_title(f'Image {i+1}')\n",
        "    ax.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "KnlixYl-2aZd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the size of the image\n",
        "image = cv2.imread(\"/content/drive/MyDrive/Traffic/train/images/00000_00000_00012_png.rf.23f94508dba03ef2f8bd187da2ec9c26.jpg\")\n",
        "h, w, c = image.shape\n",
        "print(f\"The image has dimensions {w}x{h} and {c} channels.\")"
      ],
      "metadata": {
        "id": "2KHnnFrO2aWG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use a pretrained YOLOv8n model\n",
        "model = YOLO(\"yolov8n.pt\")\n",
        "\n",
        "# Use the model to detect object\n",
        "image = \"/content/drive/MyDrive/Traffic/train/images/FisheyeCamera_1_00228_png.rf.e7c43ee9b922f7b2327b8a00ccf46a4c.jpg\"\n",
        "result_predict = model.predict(source = image, imgsz=(416))\n",
        "\n",
        "# show results\n",
        "plot = result_predict[0].plot()\n",
        "plot = cv2.cvtColor(plot, cv2.COLOR_BGR2RGB)\n",
        "display(Image.fromarray(plot))"
      ],
      "metadata": {
        "id": "kI7RaU_-2aT0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build from YAML and transfer weights\n",
        "Final_model = YOLO('yolov8n.yaml').load('yolov8n.pt')\n",
        "\n",
        "# Training The Final Model\n",
        "Result_Final_model = Final_model.train(data=\"/content/drive/MyDrive/Traffic/data.yaml\",epochs=100, imgsz = 416, batch = 64 ,lr0=0.0001, dropout= 0.15, device = 0)"
      ],
      "metadata": {
        "id": "F_8P0HC_2aRc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list_of_metrics = [\"P_curve.png\",\"R_curve.png\",\"confusion_matrix.png\"]"
      ],
      "metadata": {
        "id": "WXGPEkhk2aO5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the image\n",
        "for i in list_of_metrics:\n",
        "    image = cv2.imread(f'/kaggle/working/runs/detect/train/{i}')\n",
        "\n",
        "    # Create a larger figure\n",
        "    plt.figure(figsize=(16, 12))\n",
        "\n",
        "    # Display the image\n",
        "    plt.imshow(image)\n",
        "\n",
        "    # Show the plot\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "JlR1UOjN2aMy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Result_Final_model = pd.read_csv('/kaggle/working/runs/detect/train/results.csv')\n",
        "Result_Final_model.tail(10)"
      ],
      "metadata": {
        "id": "458wbhcR2aKJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the results.csv file as a pandas dataframe\n",
        "Result_Final_model.columns = df.columns.str.strip()\n",
        "\n",
        "# Create subplots\n",
        "fig, axs = plt.subplots(nrows=5, ncols=2, figsize=(15, 15))\n",
        "\n",
        "# Plot the columns using seaborn\n",
        "sns.lineplot(x='epoch', y='train/box_loss', data=df, ax=axs[0,0])\n",
        "sns.lineplot(x='epoch', y='train/cls_loss', data=df, ax=axs[0,1])\n",
        "sns.lineplot(x='epoch', y='train/dfl_loss', data=df, ax=axs[1,0])\n",
        "sns.lineplot(x='epoch', y='metrics/precision(B)', data=df, ax=axs[1,1])\n",
        "sns.lineplot(x='epoch', y='metrics/recall(B)', data=df, ax=axs[2,0])\n",
        "sns.lineplot(x='epoch', y='metrics/mAP50(B)', data=df, ax=axs[2,1])\n",
        "sns.lineplot(x='epoch', y='metrics/mAP50-95(B)', data=df, ax=axs[3,0])\n",
        "sns.lineplot(x='epoch', y='val/box_loss', data=df, ax=axs[3,1])\n",
        "sns.lineplot(x='epoch', y='val/cls_loss', data=df, ax=axs[4,0])\n",
        "sns.lineplot(x='epoch', y='val/dfl_loss', data=df, ax=axs[4,1])\n",
        "\n",
        "# Set titles and axis labels for each subplot\n",
        "axs[0,0].set(title='Train Box Loss')\n",
        "axs[0,1].set(title='Train Class Loss')\n",
        "axs[1,0].set(title='Train DFL Loss')\n",
        "axs[1,1].set(title='Metrics Precision (B)')\n",
        "axs[2,0].set(title='Metrics Recall (B)')\n",
        "axs[2,1].set(title='Metrics mAP50 (B)')\n",
        "axs[3,0].set(title='Metrics mAP50-95 (B)')\n",
        "axs[3,1].set(title='Validation Box Loss')\n",
        "axs[4,0].set(title='Validation Class Loss')\n",
        "axs[4,1].set(title='Validation DFL Loss')\n",
        "\n",
        "\n",
        "plt.suptitle('Training Metrics and Loss', fontsize=24)\n",
        "plt.subplots_adjust(top=0.8)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "sJBG3zjC2aHn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading the best performing model\n",
        "Valid_model = YOLO('/kaggle/working/runs/detect/train/weights/best.pt')\n",
        "\n",
        "# Evaluating the model on the testset\n",
        "metrics = Valid_model.val(split = 'test')"
      ],
      "metadata": {
        "id": "DkOEzbTU5ak6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# final results\n",
        "print(\"precision(B): \", metrics.results_dict[\"metrics/precision(B)\"])\n",
        "print(\"metrics/recall(B): \", metrics.results_dict[\"metrics/recall(B)\"])\n",
        "print(\"metrics/mAP50(B): \", metrics.results_dict[\"metrics/mAP50(B)\"])\n",
        "print(\"metrics/mAP50-95(B): \", metrics.results_dict[\"metrics/mAP50-95(B)\"])"
      ],
      "metadata": {
        "id": "XJ76oEd15ahW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Path to the directory containing the images\n",
        "image_dir = '/kaggle/input/cardetection/car/test/images'\n",
        "\n",
        "# Get a list of all image files in the directory\n",
        "image_files = [os.path.join(image_dir, file) for file in os.listdir(image_dir) if file.endswith('.jpg')]\n",
        "\n",
        "# Randomly select 10 images from the directory\n",
        "random_images = random.sample(image_files, k=10)\n",
        "\n",
        "for image_path in random_images:\n",
        "    image = cv2.imread(image_path)  # Replace with your preferred method of reading the image\n",
        "    results = Final_model.predict([image], save=True, imgsz=416, conf=0.5, iou=0.7)\n",
        "    #results.append(result)"
      ],
      "metadata": {
        "id": "5rYuEjP95ae7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# View results\n",
        "for i in range(2,12):\n",
        "    plt.imshow(plt.imread(f'/kaggle/working/runs/detect/train{i}/image0.jpg'))\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "hKFRKGVz5aH7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Export the model\n",
        "video_model.export(format='onnx')"
      ],
      "metadata": {
        "id": "B2-Gd4Oy5uFL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert mp4\n",
        "!ffmpeg -y -loglevel panic -i /kaggle/input/cardetection/video.mp4 output.mp4\n",
        "\n",
        "# Display the video\n",
        "Video(\"output.mp4\", width=960)"
      ],
      "metadata": {
        "id": "rkM9OT185uu2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load a pr-trained model\n",
        "video_model = YOLO(\"yolov8n.pt\")\n",
        "\n",
        "# Use the model to detect signs\n",
        "video_model.predict(source=\"/kaggle/input/cardetection/video.mp4\", show=True, save = True)"
      ],
      "metadata": {
        "id": "ItT-J7Oi5urd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# show result\n",
        "# Convert format\n",
        "!ffmpeg -y -loglevel panic -i /kaggle/working/runs/detect/predict/video.avi result_out.mp4\n",
        "\n",
        "# Display the video\n",
        "Video(\"result_out.mp4\", width=960)"
      ],
      "metadata": {
        "id": "-6sWJtFb5uo-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}